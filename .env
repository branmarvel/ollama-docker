# Configuración de Ollama
# Modelo a descargar automáticamente (puedes cambiarlo según tus necesidades)
# Opciones recomendadas para 16GB VRAM:
# - deepseek-coder:6.7b (ideal para programación)
# - deepseek-llm:7b (modelo general)
# - codellama:7b (especializado en código)
# - mistral:7b (modelo general de alta calidad)
OLLAMA_MODEL=deepseek-coder:6.7b

# Configuración del servidor
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434

# Configuración de GPU (no modificar)
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility